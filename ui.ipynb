{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f86a41ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ae5813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 1. SETUP & IMPORTS\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Add src to path to import our custom modules\n",
    "base_dir = \".\"\n",
    "if base_dir not in sys.path:\n",
    "    sys.path.append(base_dir)\n",
    "\n",
    "# Import our model and functions\n",
    "# (Make sure your src folder is in the same directory)\n",
    "from src.models.model import STGCN\n",
    "from src.utils.utils import z_score, z_score_inverse\n",
    "from src.data.data_processing import process_adjacency, sequence_data, split_data\n",
    "\n",
    "# Define available routes (Same as in create_data.ipynb)\n",
    "available_routes = [\n",
    "    [\"SWA\", \"NTH\", \"PTA\", \"BGN\", \"CDF\", \"NWP\", \"BPW\", \"SWI\", \"DID\", \"CHO\",\n",
    "     \"GOR\", \"PAN\", \"TLH\", \"RDG\", \"TWY\", \"MAI\", \"BNM\", \"SLO\", \"LNY\",\n",
    "     \"IVR\", \"WDT\", \"HAY\", \"STL\", \"EAL\", \"PAD\"],\n",
    "    [\"WSM\", \"WNM\", \"WOR\", \"YAT\", \"NLS\", \"BRI\", \"BTH\", \n",
    "     \"CPM\", \"SWI\", \"DID\", \"CHO\", \"GOR\", \"PAN\", \"TLH\", \"RDG\", \"TWY\", \"MAI\",\n",
    "     \"BNM\", \"SLO\", \"LNY\", \"IVR\", \"WDT\", \"HAY\", \"STL\", \"EAL\", \"PAD\"],\n",
    "    [\"BAN\", \"KGS\", \"HYD\", \"TAC\", \"OXF\", \"RAD\", \"CUM\", \"APF\", \"DID\", \"CHO\",\n",
    "     \"GOR\", \"PAN\", \"TLH\", \"RDG\", \"TWY\", \"MAI\", \"BNM\", \"SLO\", \"LNY\",\n",
    "     \"IVR\", \"WDT\", \"HAY\", \"STL\", \"EAL\", \"PAD\"]\n",
    "]\n",
    "\n",
    "def get_links(stop_1, stop_2, available_routes):\n",
    "    \"\"\"Finds all intermediate links between two stations.\"\"\"\n",
    "    done = 0\n",
    "    link_list = []\n",
    "    for i in range(len(available_routes)):\n",
    "        curr_route = available_routes[i]\n",
    "        if (stop_1 in curr_route) and (stop_2 in curr_route) and (not done):\n",
    "            done = 1\n",
    "            stop_1_idx = curr_route.index(stop_1)\n",
    "            stop_2_idx = curr_route.index(stop_2)            \n",
    "            for j in range(stop_1_idx, stop_2_idx):                \n",
    "                link_list.append(curr_route[j] + curr_route[j+1])\n",
    "    return link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "108c78de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: CPU\n",
      "Model loaded successfully (Expects 6 features).\n",
      "Stats loaded: Mean=0.0734, Std=0.8663\n",
      "Graph kernel (Lk) loaded.\n",
      "All files loaded and ready.\n"
     ]
    }
   ],
   "source": [
    "#Parameters (Must match main.py)\n",
    "n_nodes = 40\n",
    "n_timesteps_in = 12\n",
    "\n",
    "# --- CRITICAL CHANGE HERE ---\n",
    "# Changed from 1 to 6 to match your new \"Smart\" model\n",
    "n_features_in = 6  \n",
    "# ----------------------------\n",
    "\n",
    "n_features_out = 1\n",
    "ks = 5\n",
    "kt = 3\n",
    "drop_prob = 0.0\n",
    "approx = \"cheb_poly\"\n",
    "blocks = [[n_features_in, 32, 64], [64, 32, 128], [128, n_features_out]]\n",
    "\n",
    "# --- Device Setup ---\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using device: CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using Device: CPU\")\n",
    "\n",
    "# --- 1. Load Model ---\n",
    "model_path = \"./models/checkpoints/optimized_model.model\"\n",
    "stats_path = \"./models/checkpoints/output_stats.json\"\n",
    "\n",
    "# Load Model\n",
    "if not os.path.exists(model_path):\n",
    "    print(\"Error: Model not found. Please run main.py first.\")\n",
    "else:\n",
    "    model = STGCN(blocks, n_timesteps_in, n_features_out, n_nodes, device, ks, kt, drop_prob).to(device).double()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    print(f\"Model loaded successfully (Expects {n_features_in} features).\")\n",
    "\n",
    "# --- 2. Load Stats ---\n",
    "if not os.path.exists(stats_path):\n",
    "    print(\"Error: Stats file not found.\")\n",
    "    output_stats = {\"mean\": 0, \"std\": 1} # Fallback\n",
    "else:\n",
    "    with open(stats_path, 'r') as f:\n",
    "        output_stats = json.load(f)\n",
    "    print(f\"Stats loaded: Mean={output_stats['mean']:.4f}, Std={output_stats['std']:.4f}\")\n",
    "\n",
    "# --- 3. Load Graph Kernel (Lk) ---\n",
    "data_dir = \"./data/processed/\"\n",
    "Lk = process_adjacency(data_dir, \"raildelays\", ks, n_nodes, approx, device)\n",
    "print(\"Graph kernel (Lk) loaded.\")\n",
    "\n",
    "# --- 4. Load Mappings ---\n",
    "mappings = {}\n",
    "mapping_files = [\"G_stop2idx.json\", \"G_idx2stop.json\", \"LG_node2idx.json\", \"LG_idx2node.json\", \"LG_node2label.json\"]\n",
    "for f_name in mapping_files:\n",
    "    with open(os.path.join(data_dir, f_name), 'r') as f:\n",
    "        if f_name == \"LG_idx2node.json\":\n",
    "            mappings[f_name.split('.')[0]] = {int(k): v for k, v in json.load(f).items()}\n",
    "        else:\n",
    "            mappings[f_name.split('.')[0]] = json.load(f)\n",
    "\n",
    "# Helper to convert keys\n",
    "def parse_tuple_key(key_str):\n",
    "    try: return eval(key_str)\n",
    "    except: return key_str\n",
    "\n",
    "mappings[\"LG_node2label\"] = {parse_tuple_key(k): v for k, v in mappings[\"LG_node2label\"].items()}\n",
    "mappings[\"LG_node2idx\"] = {parse_tuple_key(k): v for k, v in mappings[\"LG_node2idx\"].items()}\n",
    "\n",
    "print(\"All files loaded and ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4642040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Stats from Training Data: Mean=0.0755, Std=0.8373\n",
      "Loaded test sample index: 1883\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 3. GET TEST SAMPLE (With Fixed Seed for Stability)\n",
    "# ---------------------------------------------------------\n",
    "#np.random.seed(42) # Un-comment to freeze results\n",
    "\n",
    "dataset_seq = sequence_data(data_dir, n_nodes, 42, n_timesteps_in, 1, n_features_in)\n",
    "_, _, data_test, _ = split_data(dataset_seq, n_timesteps_in)\n",
    "X_test, y_test = data_test\n",
    "\n",
    "# Pick a random sample from test set\n",
    "idx = np.random.randint(0, len(X_test))\n",
    "X_sample = X_test[idx:idx+1].permute(0, 3, 1, 2).to(device)\n",
    "y_sample = y_test[idx:idx+1].permute(0, 3, 1, 2)\n",
    "\n",
    "print(f\"Loaded test sample index: {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a5f628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 4. PREDICTION FUNCTION (The Core Logic)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def predict_route_delay(route_list):\n",
    "    # A. Identify Links in Route\n",
    "    links = []\n",
    "    link_indices = []\n",
    "    \n",
    "    for i in range(len(route_list)-1):\n",
    "        segment_links = get_links(route_list[i], route_list[i+1], available_routes)\n",
    "        links.extend(segment_links)\n",
    "        \n",
    "    if not links:\n",
    "        return None, \"No valid links found between these stations.\"\n",
    "\n",
    "    # Find indices for these links\n",
    "    for link in links:\n",
    "        found = False\n",
    "        for key, label in mappings[\"LG_node2label\"].items():\n",
    "            if label == link:\n",
    "                link_indices.append(mappings[\"LG_node2idx\"][key])\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            print(f\"Warning: Link {link} not in graph.\")\n",
    "\n",
    "    # B. Run Prediction\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_sample, Lk)\n",
    "    \n",
    "    # C. Inverse Scale (Back to Minutes)\n",
    "    pred_mins = z_score_inverse(y_pred.cpu(), output_stats[\"mean\"], output_stats[\"std\"]).numpy().squeeze()\n",
    "    actual_mins = z_score_inverse(y_sample.cpu(), output_stats[\"mean\"], output_stats[\"std\"]).numpy().squeeze()\n",
    "    \n",
    "    # D. Extract Data for Route\n",
    "    route_pred = [pred_mins[i] for i in link_indices]\n",
    "    route_actual = [actual_mins[i] for i in link_indices]\n",
    "    \n",
    "    # E. Calculate Station Delays (Cumulative)\n",
    "    # We start at 0 delay for the first station\n",
    "    station_pred = np.cumsum(route_pred)\n",
    "    station_actual = np.cumsum(route_actual)\n",
    "    error = station_pred - station_actual\n",
    "    \n",
    "    # F. Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Link\": links,\n",
    "        \"Pred Link Delay\": route_pred,\n",
    "        \"Actual Link Delay\": route_actual,\n",
    "        \"Pred Station Delay\": station_pred,\n",
    "        \"Actual Station Delay\": station_actual,\n",
    "        \"Error\": error\n",
    "    })\n",
    "    \n",
    "    return df, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df8022a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 5. VISUALIZATION FUNCTION (Plotly)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def show_results(df, route_str):\n",
    "    # 1. Station Delay Plot\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=df[\"Link\"], y=df[\"Pred Station Delay\"], mode='lines+markers', name='Predicted Delay', line=dict(color='blue', width=3)))\n",
    "    fig.add_trace(go.Scatter(x=df[\"Link\"], y=df[\"Actual Station Delay\"], mode='lines+markers', name='Actual Delay', line=dict(color='red', width=3, dash='dash')))\n",
    "    fig.update_layout(title=f\"Station-Wise Delay: {route_str}\", xaxis_title=\"Link (Station to Station)\", yaxis_title=\"Total Delay (min)\", template=\"plotly_white\")\n",
    "    \n",
    "    # 2. Error Plot\n",
    "    fig_err = go.Figure()\n",
    "    fig_err.add_trace(go.Bar(x=df[\"Link\"], y=df[\"Error\"], name=\"Prediction Error\", marker_color=\"purple\"))\n",
    "    fig_err.update_layout(title=\"Prediction Error per Station\", xaxis_title=\"Link\", yaxis_title=\"Error (min)\", template=\"plotly_white\")\n",
    "    \n",
    "    # 3. Display\n",
    "    fig.show()\n",
    "    fig_err.show()\n",
    "    \n",
    "    # 4. Data Table with Styling\n",
    "    # Use .map instead of .applymap for newer pandas versions\n",
    "    def color_val(val):\n",
    "        color = 'red' if abs(val) > 2 else 'green'\n",
    "        return f'color: {color}'\n",
    "    \n",
    "    display(df.style.format(\"{:.2f} min\", subset=[\"Pred Link Delay\", \"Actual Link Delay\", \"Pred Station Delay\", \"Actual Station Delay\", \"Error\"])\n",
    "            .map(color_val, subset=[\"Error\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca97a752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4182c1e8744b119fb35ad34d5b0abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='SWA,NTH,PTA,BGN,CDF,NWP,BPW,SWI,DID,RDG,PAD', description='<b>Route:</b>', layout=Lâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 6. USER INTERFACE\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "text_input = widgets.Text(\n",
    "    value='SWA,NTH,PTA,BGN,CDF,NWP,BPW,SWI,DID,RDG,PAD',\n",
    "    placeholder='Type station codes (e.g., SWA,PAD)',\n",
    "    description='<b>Route:</b>',\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "btn = widgets.Button(\n",
    "    description='Predict',\n",
    "    button_style='primary',\n",
    "    icon='train'\n",
    ")\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "def on_click(b):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        route = [x.strip().upper() for x in text_input.value.split(',')]\n",
    "        if len(route) < 2:\n",
    "            print(\"Error: Enter at least 2 stations.\")\n",
    "            return\n",
    "            \n",
    "        print(f\"Processing route: {' -> '.join(route)}...\")\n",
    "        df_res, err = predict_route_delay(route)\n",
    "        \n",
    "        if err:\n",
    "            print(err)\n",
    "        else:\n",
    "            show_results(df_res, text_input.value)\n",
    "\n",
    "btn.on_click(on_click)\n",
    "\n",
    "display(widgets.VBox([text_input, btn, out]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
